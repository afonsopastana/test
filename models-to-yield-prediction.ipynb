{"cells":[{"cell_type":"markdown","metadata":{},"source":["# YIELD PREDICTION \n","Data : All dataset(publicly available dataset) here are taken form [FAO (Food and Agriculture Organization)](http://www.fao.org/home/en/) and [World Data Bank](https://data.worldbank.org/).\n","### Summary:\n","* Importing and assembling data set.\n","* Exploratory analysis\n","* Models propositions:\n","    * Linear Regression.\n","    * XGBoosting\n","    * Random Forest \n","    * Gradient Boosting \n","    * Decision Tree\n","    * Bagging Regressor\n","    * Support Vector Regression\n","* Hyperparameter tuning.\n","* Model retained and conclusions."]},{"cell_type":"markdown","metadata":{},"source":["# Importing and assembling data set"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-22T08:26:44.689134Z","iopub.status.busy":"2023-11-22T08:26:44.688762Z","iopub.status.idle":"2023-11-22T08:26:45.127063Z","shell.execute_reply":"2023-11-22T08:26:45.125944Z","shell.execute_reply.started":"2023-11-22T08:26:44.689103Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt \n","import seaborn as sns\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('dataset'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"markdown","metadata":{},"source":["While this notebook has the intention of been and excercise / review / first steps for our final ML project. I use the 4 original files to do my own Data-frame.\n","\n","Taking acount that the files containing the information about pesticides, rainfall and temperatures are linked to a geographic zone, we're going to try to create a unique DF containing all the data attached to a geographic zone and a year."]},{"cell_type":"markdown","metadata":{},"source":["### Working in yield"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T08:26:55.881552Z","iopub.status.busy":"2023-11-22T08:26:55.881001Z","iopub.status.idle":"2023-11-22T08:26:56.092413Z","shell.execute_reply":"2023-11-22T08:26:56.091246Z","shell.execute_reply.started":"2023-11-22T08:26:55.881517Z"},"trusted":true},"outputs":[],"source":["df_yield = pd.read_csv(dirname + \"/\" + filenames[1])\n","df_yield.head()"]},{"cell_type":"markdown","metadata":{},"source":["We analyse the information inside the 'yield' dataframe, and than select those attributs of interest"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_yield.Domain.describe() # unique = 1 this coloumn isn't giving us new information, we can eliminate it.\n","df_yield['Domain Code'].describe()# unique = 1 this coloumn isn't giving us new information, we can eliminate it.\n","tmp = np.where(df_yield['Year Code'] != df_yield['Year']) # This 2 columns have exactly the same info.\n","df_yield['Unit'].describe() # unique = 1 this coloumn isn't giving us new information, we can eliminate it.\n","df_yield['Element'].describe() # unique = 1 this coloumn isn't giving us new information, we can eliminate it.\n","df_yield['Area'].describe() #212 countries\n","\n","# So, we create the new dataset putting only the meaningful data we found.\n","df = df_yield.loc[:,['Area','Item','Year','Value']]\n","df.shape"]},{"cell_type":"markdown","metadata":{},"source":["### Working in temp"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T08:31:44.593133Z","iopub.status.busy":"2023-11-22T08:31:44.592718Z","iopub.status.idle":"2023-11-22T08:31:44.667431Z","shell.execute_reply":"2023-11-22T08:31:44.666363Z","shell.execute_reply.started":"2023-11-22T08:31:44.593099Z"},"trusted":true},"outputs":[],"source":["df_temp = pd.read_csv(dirname + \"/\" + filenames[4])\n","df_temp.columns = df_temp.columns.str.replace('year', 'Year')\n","df_temp.columns = df_temp.columns.str.replace('country', 'Area')\n","df_temp.head()"]},{"cell_type":"markdown","metadata":{},"source":["Here we merge 'yield' and 'temp' datasets. The primary key used to do so is an ensemble 'Year' and 'Area'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T01:00:41.884897Z","iopub.status.busy":"2023-11-21T01:00:41.884506Z","iopub.status.idle":"2023-11-21T01:00:41.927335Z","shell.execute_reply":"2023-11-21T01:00:41.926108Z","shell.execute_reply.started":"2023-11-21T01:00:41.884860Z"},"trusted":true},"outputs":[],"source":["# merging both data frames by Year and Area\n","df = pd.merge(df, df_temp, how='inner', on = ['Year', 'Area'])\n","df.columns = df.columns.str.replace('Value', \"yield_hg/ha\")\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T01:00:41.929329Z","iopub.status.busy":"2023-11-21T01:00:41.928941Z","iopub.status.idle":"2023-11-21T01:00:41.941098Z","shell.execute_reply":"2023-11-21T01:00:41.940073Z","shell.execute_reply.started":"2023-11-21T01:00:41.929294Z"},"trusted":true},"outputs":[],"source":["print(df.isna().sum())\n","# I confirmed there's not NaNs ! In this case we apparently have a super good quality dataset."]},{"cell_type":"markdown","metadata":{},"source":["### Working in rainfall"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T01:00:41.942559Z","iopub.status.busy":"2023-11-21T01:00:41.942244Z","iopub.status.idle":"2023-11-21T01:00:41.974730Z","shell.execute_reply":"2023-11-21T01:00:41.973558Z","shell.execute_reply.started":"2023-11-21T01:00:41.942529Z"},"trusted":true},"outputs":[],"source":["df_rainfall = pd.read_csv(dirname + \"/\" + filenames[3])\n","df_rainfall.columns = df_rainfall.columns.str.replace('average_rain_fall_mm_per_year', 'rain_mm_year')\n","df_rainfall.columns = df_rainfall.columns.str.replace(' Area', 'Area')\n","df_rainfall"]},{"cell_type":"markdown","metadata":{},"source":["Merging the 'rainfall' information into the dataframe we had so far"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T01:00:41.976656Z","iopub.status.busy":"2023-11-21T01:00:41.976027Z","iopub.status.idle":"2023-11-21T01:00:42.005645Z","shell.execute_reply":"2023-11-21T01:00:42.004538Z","shell.execute_reply.started":"2023-11-21T01:00:41.976624Z"},"trusted":true},"outputs":[],"source":["df = pd.merge(df, df_rainfall, how='inner', on = ['Year', 'Area'])\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T01:00:42.006969Z","iopub.status.busy":"2023-11-21T01:00:42.006704Z","iopub.status.idle":"2023-11-21T01:00:42.018635Z","shell.execute_reply":"2023-11-21T01:00:42.016446Z","shell.execute_reply.started":"2023-11-21T01:00:42.006946Z"},"trusted":true},"outputs":[],"source":["print(df.isna().sum())"]},{"cell_type":"markdown","metadata":{},"source":["### Working in pesticides"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T01:00:42.020991Z","iopub.status.busy":"2023-11-21T01:00:42.020403Z","iopub.status.idle":"2023-11-21T01:00:42.044922Z","shell.execute_reply":"2023-11-21T01:00:42.044263Z","shell.execute_reply.started":"2023-11-21T01:00:42.020959Z"},"trusted":true},"outputs":[],"source":["df_pesticides = pd.read_csv(dirname + \"/\" + filenames[2])\n","df_pesticides.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T01:00:42.048152Z","iopub.status.busy":"2023-11-21T01:00:42.047091Z","iopub.status.idle":"2023-11-21T01:00:42.058628Z","shell.execute_reply":"2023-11-21T01:00:42.057685Z","shell.execute_reply.started":"2023-11-21T01:00:42.048123Z"},"trusted":true},"outputs":[],"source":["df_pesticides.Item.describe() # unique = 1 this coloumn isn't giving us new information, we can eliminate it.\n","df_pesticides.Element.describe() # unique = 1 this coloumn isn't giving us new information, we can eliminate it.\n","df_pesticides.Domain.describe() # unique = 1 this coloumn isn't giving us new information, we can eliminate it.\n","df_pesticides.Unit.describe() # unique = 1 this coloumn isn't giving us new information, we can eliminate it.\n","df_pesticides.columns = df_pesticides.columns.str.replace('Value', 'ton_pest')\n"]},{"cell_type":"markdown","metadata":{},"source":["After selecting the attributs of interest we merge this data frame with the previous one"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T01:00:42.060883Z","iopub.status.busy":"2023-11-21T01:00:42.060347Z","iopub.status.idle":"2023-11-21T01:00:42.095557Z","shell.execute_reply":"2023-11-21T01:00:42.094414Z","shell.execute_reply.started":"2023-11-21T01:00:42.060840Z"},"trusted":true},"outputs":[],"source":["df = pd.merge(df, df_pesticides.loc[:,['Area', 'Year', 'ton_pest']], how='inner', on = ['Year', 'Area'])\n","print(df.isna().sum())\n","df  # So far we have no NA's in our data set"]},{"cell_type":"markdown","metadata":{},"source":["At this point we have a complete data set, the ideal now is to explore this dataset using some exploratory statistics techniques to understand the dependences, correlations and patterns between attributs."]},{"cell_type":"markdown","metadata":{},"source":["## cleaning dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T01:00:42.097138Z","iopub.status.busy":"2023-11-21T01:00:42.096849Z","iopub.status.idle":"2023-11-21T01:00:42.113395Z","shell.execute_reply":"2023-11-21T01:00:42.111816Z","shell.execute_reply.started":"2023-11-21T01:00:42.097114Z"},"trusted":true},"outputs":[],"source":["df.info()"]},{"cell_type":"markdown","metadata":{},"source":["We notice that 'rain_mm_year' is a data of type 'object' when it should be of a numeric type. After some investigation, it's possible to see that there were some values in this column that were no valid information, represented by two dots. We drop these values out and keep the new DF with 'rain_mm_year' as a float data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-21T01:00:42.115390Z","iopub.status.busy":"2023-11-21T01:00:42.115055Z","iopub.status.idle":"2023-11-21T01:00:42.154092Z","shell.execute_reply":"2023-11-21T01:00:42.152942Z","shell.execute_reply.started":"2023-11-21T01:00:42.115364Z"},"trusted":true},"outputs":[],"source":["# We have just to correct the dataType of rain_mm_year\n","# There is something that we can't not convert in float, to find it we used an easy approach with a for cycle and a try-except control structure.\n","for raindata in df.rain_mm_year:\n","    try:\n","        raindata = float(raindata)\n","    except:\n","        print(raindata)\n","        \n","tmp = np.where(df.rain_mm_year == '..')\n","df = df.drop(list(tmp[0]))\n","# Now we can do the correct dataType to the attribute\n","\n","df.rain_mm_year = df.rain_mm_year.astype('float')\n","df.info()"]},{"cell_type":"markdown","metadata":{},"source":["# Exploratory analyses"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.Year = df.Year.astype('object')\n","df.describe().T"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.describe(include = 'object').T"]},{"cell_type":"markdown","metadata":{},"source":["## Normalization"]},{"cell_type":"markdown","metadata":{},"source":["In this section we perform a normalization in the yield value (```yield_hg/ha```). We do so because these values come from heterogeneous cultures, that have differents weights.\n","\n","The normalization allows un to compare these values of production, even between different plants.\n","\n","The normalization we perform here is based in the amplitude of production of a given vegetable, therefore the normalization is made **by culture**. This specifc approach by amplitude is called ```Min-Max Normalization```, and can be mathmatically expressed as follow:\n","$$\n","y_{\\text{norm}} = \\frac{y - min}{max - min}\n","$$"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cultures = df.Item.unique()\n","# take the min and max values for each culture of plants\n","maxmin_cultures = {culture:(df.loc[df['Item'] == culture, 'yield_hg/ha'].max(), df.loc[df['Item'] == culture, 'yield_hg/ha'].min()) for culture in cultures}\n","\n","# apply the min-max normalization\n","yield_norm = []\n","for ligne in df.iterrows():\n","    l = ligne[1]\n","    n = (l['yield_hg/ha'] - maxmin_cultures[l.Item][1])/(maxmin_cultures[l.Item][0] - maxmin_cultures[l.Item][1])\n","    yield_norm.append(n)\n","\n","# add the normalized yield values in the data frame\n","df['yield_norm'] = yield_norm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.info()\n","# new data frame, with normalized yield values"]},{"cell_type":"markdown","metadata":{},"source":["## Linear correlation between attributs"]},{"cell_type":"markdown","metadata":{},"source":["In order to capture the correlation between all the attributs we have to encode those that are 'objects' to a numeric value. We'll do so using a label enconder, from the sklearn package"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","df2 = df.copy()\n","labelencoder = LabelEncoder()\n","# encoding 'Area' (countries)\n","df2.iloc[:, 0] = labelencoder.fit_transform(df2.iloc[:, 0]) \n","# encoding 'Item' (cultures)\n","df2.iloc[:, 1] = labelencoder.fit_transform(df2.iloc[:, 1]) \n","df2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# calculate correlation and plot \n","corr_matrix = df2.loc[:,['Area', 'Year', 'Item', 'yield_hg/ha','avg_temp','rain_mm_year', 'ton_pest', 'yield_norm']].corr()\n","print(corr_matrix)\n","sns.heatmap(corr_matrix, annot=True, cmap='Greens')"]},{"cell_type":"markdown","metadata":{},"source":["Some remarkable correlations are between the amount of pesticide and the country ('ton_pest', 'Area'); the correlation between rainfall and temperature ('rain_mm_year', 'avg_temp'); and between the rainfall and the amount of pesticides ('ton_pest', 'rain_mm_year')"]},{"cell_type":"markdown","metadata":{},"source":["## Graphique\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["count_crops = df.groupby('Year')['yield_hg/ha'].mean()\n","count_crops.plot(color='green')\n","\n","count_crops = df.groupby('Year')['ton_pest'].mean()\n","count_crops.plot(color='red')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.hist(df['yield_norm'], bins=100)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Model propositions"]},{"cell_type":"markdown","metadata":{},"source":["In this section some models will be proposed in order to predict yield values. As the values we are trying to predict are continuous, the models will be used to perform a regression."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_mod = df.copy()\n","df_mod"]},{"cell_type":"markdown","metadata":{},"source":["We're not considering the feature ```Year``` since we have the goal of predicting futures values of yield production."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["numeric_attributs = ['avg_temp', 'rain_mm_year', 'ton_pest']\n","categorical_attributs = ['Area', 'Item']"]},{"cell_type":"markdown","metadata":{},"source":["From this point, we're proposing some tests on the data preprocessing in order to evaluate their effect on the accuracy of the regresion model.\n","\n","We propose to fit models using four heterogeneos data sets: \n","* one with categorical values encoded by ```LabelEncoder()``` in the ```X``` data frame, and the ```y``` data frame with **non normalized** yield values; \n","* the second data set will have the same encoding, but the ```y``` values **normalized**; \n","* the third will have the categorical values encoded with ```One Hot Encoding``` and **non normalized** yield production values; \n","* the last one will have the same encoding as the third one, but now the ```y``` data frame will be **normalized**.\n","\n","All the values in the feature's data frame (```X```) will be normalized using ```MinMaxScaler()```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# definig features and labels data frames\n","\n","# selecting the attributs data frame\n","featuresX = df_mod[numeric_attributs + categorical_attributs]\n","\n","# selecting labels' data frame\n","y_Nnorm = df_mod['yield_hg/ha'] # Nnorm means \"Non normalized\"\n","y_norm = df_mod['yield_norm'] # norm are \"normalized\" values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","# enconding categorical values\n","# encoding with LabelEncoder()\n","X_le = featuresX.copy() # X_le means X encoded with label encoder\n","label_encoder = LabelEncoder()\n","for column in categorical_attributs:\n","    X_le[column] = label_encoder.fit_transform(featuresX[column])\n","\n","# encoding with One Hot encoding\n","X_oh = pd.get_dummies(featuresX, columns=['Area',\"Item\"]) # X_oh means X encoded with One Hot\n","\n","# normalizing both feature's data frame with min-max normalization\n","scaler = MinMaxScaler()\n","X_le = scaler.fit_transform(X_le)\n","X_oh = scaler.fit_transform(X_oh)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# assembling data sets in a dictionary makes the work easier\n","data_sets = {'one hot, non norm': [X_oh, y_Nnorm], 'one hot, norm': [X_oh, y_norm], 'label enc, non norm': [X_le, y_Nnorm], 'label enc, norm': [X_le, y_norm]}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import ShuffleSplit\n","\n","# function to calculate the performance of the model with cross validation\n","def fitPredict_score(model, dic_data_sets):\n","    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n","    scoring = ['r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_error']\n","    scores = cross_validate(model, dic_data_sets[0], dic_data_sets[1],\n","                            cv=cv, scoring=scoring)\n","    return scores\n","\n","# create data frame where theses values of performance will be stored\n","final_results = pd.DataFrame(columns=['type', 'model', 'r2', 'rmse', 'mae'])"]},{"cell_type":"markdown","metadata":{},"source":["```R2``` is a goodness-of-fit measure for linear regression models. This statistic indicates the percentage of the variance in the dependent variable that the independent variables explain collectively. Also, in scikit-learn the method ```score()```, when used with regression models, returns the ```R2``` value as a mesure to the quality of the model. It's considered as the accuracy of a regression model. That's why this will be our main reference to select a good model.\n","\n","Besides the ```R2``` we also calculate ```RMSE``` (root mean square error) and ```MAE``` (mean absolute error). Althoutght these are good mesures to evaluate the performance of a regression model, it's more problematic in our case for two reasons: first because we are trying differents data sets, one where ```y``` (yield) is normalized and other where it is not, therefore the values of ```RMSE``` et ```MAE``` from both cases are in different scales and it becomes hard to compare which one of the data sets returns the best value for these metrics; the second reason affects just for the non normalized ```y```, as we have different cultures it is hard to know if these errors are disturbingly high (ex.: an error of 200 kg in the prediction for rice is way more expressive than this same error in a prediction where the vegetable is potatoe)."]},{"cell_type":"markdown","metadata":{},"source":["## Linear Regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","\n","\n","clf = LinearRegression()\n","\n","\n","cv_oh_n = fitPredict_score(clf, data_sets['one hot, norm'])\n","cv_oh_nn = fitPredict_score(clf, data_sets['one hot, non norm'])\n","cv_le_n = fitPredict_score(clf, data_sets['label enc, norm'])\n","cv_le_nn = fitPredict_score(clf, data_sets['label enc, non norm'])\n","\n","print('Scores for One Hot encoding and Normalized yield values:')\n","print('R2 score: ', cv_oh_n['test_r2'].mean())\n","print('RMSE score: ', cv_oh_n['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_oh_n['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for One Hot encoding and NON Normalized yield values:')\n","print('R2 score: ', cv_oh_nn['test_r2'].mean())\n","print('RMSE score: ', cv_oh_nn['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_oh_nn['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for Label encoding and Normalized yield values:')\n","print('R2 score: ', cv_le_n['test_r2'].mean())\n","print('RMSE score: ', cv_le_n['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_le_n['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for Label encoding and NON Normalized yield values:')\n","print('R2 score: ', cv_le_nn['test_r2'].mean())\n","print('RMSE score: ', cv_le_nn['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_le_nn['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","results = pd.DataFrame({'type': ['One hot, norm', 'One hot, non norm', 'Label enc, norm', 'Label enc, non norm'],\n","                              'model': np.array('linear regression').repeat(4),\n","                              'r2': [cv_oh_n['test_r2'].mean(), cv_oh_nn['test_r2'].mean(), cv_le_n['test_r2'].mean(), cv_le_nn['test_r2'].mean()],\n","                              'rmse': [cv_oh_n['test_neg_root_mean_squared_error'].mean()*-1, cv_oh_nn['test_neg_root_mean_squared_error'].mean()*-1,\n","                                       cv_le_n['test_neg_root_mean_squared_error'].mean()*-1, cv_le_nn['test_neg_root_mean_squared_error'].mean()*-1],\n","                              'mae': [cv_oh_n['test_neg_mean_absolute_error'].mean()*-1, cv_oh_nn['test_neg_mean_absolute_error'].mean()*-1, \n","                                      cv_le_n['test_neg_mean_absolute_error'].mean()*-1, cv_le_nn['test_neg_mean_absolute_error'].mean()*-1]})\n","final_results = pd.concat([final_results, results])"]},{"cell_type":"markdown","metadata":{},"source":["## XGBoosting"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import xgboost as xg\n","\n","\n","clf = xg.XGBRegressor(random_state=42)\n","\n","cv_oh_n = fitPredict_score(clf, data_sets['one hot, norm'])\n","cv_oh_nn = fitPredict_score(clf, data_sets['one hot, non norm'])\n","cv_le_n = fitPredict_score(clf, data_sets['label enc, norm'])\n","cv_le_nn = fitPredict_score(clf, data_sets['label enc, non norm'])\n","\n","print('Scores for One Hot encoding and Normalized yield values:')\n","print('R2 score: ', cv_oh_n['test_r2'].mean())\n","print('RMSE score: ', cv_oh_n['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_oh_n['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for One Hot encoding and NON Normalized yield values:')\n","print('R2 score: ', cv_oh_nn['test_r2'].mean())\n","print('RMSE score: ', cv_oh_nn['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_oh_nn['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for Label encoding and Normalized yield values:')\n","print('R2 score: ', cv_le_n['test_r2'].mean())\n","print('RMSE score: ', cv_le_n['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_le_n['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for Label encoding and NON Normalized yield values:')\n","print('R2 score: ', cv_le_nn['test_r2'].mean())\n","print('RMSE score: ', cv_le_nn['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_le_nn['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","results = pd.DataFrame({'type': ['One hot, norm', 'One hot, non norm', 'Label enc, norm', 'Label enc, non norm'],\n","                              'model': np.array('xgboosting').repeat(4),\n","                              'r2': [cv_oh_n['test_r2'].mean(), cv_oh_nn['test_r2'].mean(), cv_le_n['test_r2'].mean(), cv_le_nn['test_r2'].mean()],\n","                              'rmse': [cv_oh_n['test_neg_root_mean_squared_error'].mean()*-1, cv_oh_nn['test_neg_root_mean_squared_error'].mean()*-1,\n","                                       cv_le_n['test_neg_root_mean_squared_error'].mean()*-1, cv_le_nn['test_neg_root_mean_squared_error'].mean()*-1],\n","                              'mae': [cv_oh_n['test_neg_mean_absolute_error'].mean()*-1, cv_oh_nn['test_neg_mean_absolute_error'].mean()*-1, \n","                                      cv_le_n['test_neg_mean_absolute_error'].mean()*-1, cv_le_nn['test_neg_mean_absolute_error'].mean()*-1]})\n","final_results = pd.concat([final_results, results])"]},{"cell_type":"markdown","metadata":{},"source":["## Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import RandomForestRegressor\n","\n","\n","clf = RandomForestRegressor(random_state=42)\n","\n","cv_oh_n = fitPredict_score(clf, data_sets['one hot, norm'])\n","cv_oh_nn = fitPredict_score(clf, data_sets['one hot, non norm'])\n","cv_le_n = fitPredict_score(clf, data_sets['label enc, norm'])\n","cv_le_nn = fitPredict_score(clf, data_sets['label enc, non norm'])\n","\n","print('Scores for One Hot encoding and Normalized yield values:')\n","print('R2 score: ', cv_oh_n['test_r2'].mean())\n","print('RMSE score: ', cv_oh_n['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_oh_n['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for One Hot encoding and NON Normalized yield values:')\n","print('R2 score: ', cv_oh_nn['test_r2'].mean())\n","print('RMSE score: ', cv_oh_nn['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_oh_nn['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for Label encoding and Normalized yield values:')\n","print('R2 score: ', cv_le_n['test_r2'].mean())\n","print('RMSE score: ', cv_le_n['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_le_n['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for Label encoding and NON Normalized yield values:')\n","print('R2 score: ', cv_le_nn['test_r2'].mean())\n","print('RMSE score: ', cv_le_nn['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_le_nn['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","results = pd.DataFrame({'type': ['One hot, norm', 'One hot, non norm', 'Label enc, norm', 'Label enc, non norm'],\n","                              'model': np.array('random forest').repeat(4),\n","                              'r2': [cv_oh_n['test_r2'].mean(), cv_oh_nn['test_r2'].mean(), cv_le_n['test_r2'].mean(), cv_le_nn['test_r2'].mean()],\n","                              'rmse': [cv_oh_n['test_neg_root_mean_squared_error'].mean()*-1, cv_oh_nn['test_neg_root_mean_squared_error'].mean()*-1,\n","                                       cv_le_n['test_neg_root_mean_squared_error'].mean()*-1, cv_le_nn['test_neg_root_mean_squared_error'].mean()*-1],\n","                              'mae': [cv_oh_n['test_neg_mean_absolute_error'].mean()*-1, cv_oh_nn['test_neg_mean_absolute_error'].mean()*-1, \n","                                      cv_le_n['test_neg_mean_absolute_error'].mean()*-1, cv_le_nn['test_neg_mean_absolute_error'].mean()*-1]})\n","final_results = pd.concat([final_results, results])"]},{"cell_type":"markdown","metadata":{},"source":["## Gradient Boosting regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingRegressor\n","\n","\n","clf = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3,random_state=42)\n","\n","cv_oh_n = fitPredict_score(clf, data_sets['one hot, norm'])\n","cv_oh_nn = fitPredict_score(clf, data_sets['one hot, non norm'])\n","cv_le_n = fitPredict_score(clf, data_sets['label enc, norm'])\n","cv_le_nn = fitPredict_score(clf, data_sets['label enc, non norm'])\n","\n","print('Scores for One Hot encoding and Normalized yield values:')\n","print('R2 score: ', cv_oh_n['test_r2'].mean())\n","print('RMSE score: ', cv_oh_n['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_oh_n['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for One Hot encoding and NON Normalized yield values:')\n","print('R2 score: ', cv_oh_nn['test_r2'].mean())\n","print('RMSE score: ', cv_oh_nn['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_oh_nn['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for Label encoding and Normalized yield values:')\n","print('R2 score: ', cv_le_n['test_r2'].mean())\n","print('RMSE score: ', cv_le_n['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_le_n['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for Label encoding and NON Normalized yield values:')\n","print('R2 score: ', cv_le_nn['test_r2'].mean())\n","print('RMSE score: ', cv_le_nn['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_le_nn['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","results = pd.DataFrame({'type': ['One hot, norm', 'One hot, non norm', 'Label enc, norm', 'Label enc, non norm'],\n","                              'model': np.array('gradient boosting').repeat(4),\n","                              'r2': [cv_oh_n['test_r2'].mean(), cv_oh_nn['test_r2'].mean(), cv_le_n['test_r2'].mean(), cv_le_nn['test_r2'].mean()],\n","                              'rmse': [cv_oh_n['test_neg_root_mean_squared_error'].mean()*-1, cv_oh_nn['test_neg_root_mean_squared_error'].mean()*-1,\n","                                       cv_le_n['test_neg_root_mean_squared_error'].mean()*-1, cv_le_nn['test_neg_root_mean_squared_error'].mean()*-1],\n","                              'mae': [cv_oh_n['test_neg_mean_absolute_error'].mean()*-1, cv_oh_nn['test_neg_mean_absolute_error'].mean()*-1, \n","                                      cv_le_n['test_neg_mean_absolute_error'].mean()*-1, cv_le_nn['test_neg_mean_absolute_error'].mean()*-1]})\n","final_results = pd.concat([final_results, results])"]},{"cell_type":"markdown","metadata":{},"source":["## Decision tree regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.tree import DecisionTreeRegressor\n","\n","\n","clf = DecisionTreeRegressor(random_state=42)\n","\n","cv_oh_n = fitPredict_score(clf, data_sets['one hot, norm'])\n","cv_oh_nn = fitPredict_score(clf, data_sets['one hot, non norm'])\n","cv_le_n = fitPredict_score(clf, data_sets['label enc, norm'])\n","cv_le_nn = fitPredict_score(clf, data_sets['label enc, non norm'])\n","\n","print('Scores for One Hot encoding and Normalized yield values:')\n","print('R2 score: ', cv_oh_n['test_r2'].mean())\n","print('RMSE score: ', cv_oh_n['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_oh_n['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for One Hot encoding and NON Normalized yield values:')\n","print('R2 score: ', cv_oh_nn['test_r2'].mean())\n","print('RMSE score: ', cv_oh_nn['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_oh_nn['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for Label encoding and Normalized yield values:')\n","print('R2 score: ', cv_le_n['test_r2'].mean())\n","print('RMSE score: ', cv_le_n['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_le_n['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for Label encoding and NON Normalized yield values:')\n","print('R2 score: ', cv_le_nn['test_r2'].mean())\n","print('RMSE score: ', cv_le_nn['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_le_nn['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","results = pd.DataFrame({'type': ['One hot, norm', 'One hot, non norm', 'Label enc, norm', 'Label enc, non norm'],\n","                              'model': np.array('decision tree').repeat(4),\n","                              'r2': [cv_oh_n['test_r2'].mean(), cv_oh_nn['test_r2'].mean(), cv_le_n['test_r2'].mean(), cv_le_nn['test_r2'].mean()],\n","                              'rmse': [cv_oh_n['test_neg_root_mean_squared_error'].mean()*-1, cv_oh_nn['test_neg_root_mean_squared_error'].mean()*-1,\n","                                       cv_le_n['test_neg_root_mean_squared_error'].mean()*-1, cv_le_nn['test_neg_root_mean_squared_error'].mean()*-1],\n","                              'mae': [cv_oh_n['test_neg_mean_absolute_error'].mean()*-1, cv_oh_nn['test_neg_mean_absolute_error'].mean()*-1, \n","                                      cv_le_n['test_neg_mean_absolute_error'].mean()*-1, cv_le_nn['test_neg_mean_absolute_error'].mean()*-1]})\n","final_results = pd.concat([final_results, results])"]},{"cell_type":"markdown","metadata":{},"source":["## Bagging Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import BaggingRegressor\n","from sklearn.svm import SVR\n","\n","\n","clf = BaggingRegressor(n_estimators=150, random_state=42)\n","\n","cv_oh_n = fitPredict_score(clf, data_sets['one hot, norm'])\n","cv_oh_nn = fitPredict_score(clf, data_sets['one hot, non norm'])\n","cv_le_n = fitPredict_score(clf, data_sets['label enc, norm'])\n","cv_le_nn = fitPredict_score(clf, data_sets['label enc, non norm'])\n","\n","print('Scores for One Hot encoding and Normalized yield values:')\n","print('R2 score: ', cv_oh_n['test_r2'].mean())\n","print('RMSE score: ', cv_oh_n['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_oh_n['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for One Hot encoding and NON Normalized yield values:')\n","print('R2 score: ', cv_oh_nn['test_r2'].mean())\n","print('RMSE score: ', cv_oh_nn['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_oh_nn['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for Label encoding and Normalized yield values:')\n","print('R2 score: ', cv_le_n['test_r2'].mean())\n","print('RMSE score: ', cv_le_n['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_le_n['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for Label encoding and NON Normalized yield values:')\n","print('R2 score: ', cv_le_nn['test_r2'].mean())\n","print('RMSE score: ', cv_le_nn['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_le_nn['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","results = pd.DataFrame({'type': ['One hot, norm', 'One hot, non norm', 'Label enc, norm', 'Label enc, non norm'],\n","                              'model': np.array('bagging regressor').repeat(4),\n","                              'r2': [cv_oh_n['test_r2'].mean(), cv_oh_nn['test_r2'].mean(), cv_le_n['test_r2'].mean(), cv_le_nn['test_r2'].mean()],\n","                              'rmse': [cv_oh_n['test_neg_root_mean_squared_error'].mean()*-1, cv_oh_nn['test_neg_root_mean_squared_error'].mean()*-1,\n","                                       cv_le_n['test_neg_root_mean_squared_error'].mean()*-1, cv_le_nn['test_neg_root_mean_squared_error'].mean()*-1],\n","                              'mae': [cv_oh_n['test_neg_mean_absolute_error'].mean()*-1, cv_oh_nn['test_neg_mean_absolute_error'].mean()*-1, \n","                                      cv_le_n['test_neg_mean_absolute_error'].mean()*-1, cv_le_nn['test_neg_mean_absolute_error'].mean()*-1]})\n","final_results = pd.concat([final_results, results])"]},{"cell_type":"markdown","metadata":{},"source":["## Support Vector Regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.svm import SVR\n","\n","\n","clf = SVR(kernel=\"rbf\", C=100, gamma=0.1, epsilon=0.1)\n","\n","cv_oh_n = fitPredict_score(clf, data_sets['one hot, norm'])\n","cv_oh_nn = fitPredict_score(clf, data_sets['one hot, non norm'])\n","cv_le_n = fitPredict_score(clf, data_sets['label enc, norm'])\n","cv_le_nn = fitPredict_score(clf, data_sets['label enc, non norm'])\n","\n","print('Scores for One Hot encoding and Normalized yield values:')\n","print('R2 score: ', cv_oh_n['test_r2'].mean())\n","print('RMSE score: ', cv_oh_n['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_oh_n['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for One Hot encoding and NON Normalized yield values:')\n","print('R2 score: ', cv_oh_nn['test_r2'].mean())\n","print('RMSE score: ', cv_oh_nn['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_oh_nn['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for Label encoding and Normalized yield values:')\n","print('R2 score: ', cv_le_n['test_r2'].mean())\n","print('RMSE score: ', cv_le_n['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_le_n['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","print('Scores for Label encoding and NON Normalized yield values:')\n","print('R2 score: ', cv_le_nn['test_r2'].mean())\n","print('RMSE score: ', cv_le_nn['test_neg_root_mean_squared_error'].mean()*-1)\n","print('MAE score: ', cv_le_nn['test_neg_mean_absolute_error'].mean()*-1)\n","print('-'*70)\n","\n","results = pd.DataFrame({'type': ['One hot, norm', 'One hot, non norm', 'Label enc, norm', 'Label enc, non norm'],\n","                              'model': np.array('SVR rbf').repeat(4),\n","                              'r2': [cv_oh_n['test_r2'].mean(), cv_oh_nn['test_r2'].mean(), cv_le_n['test_r2'].mean(), cv_le_nn['test_r2'].mean()],\n","                              'rmse': [cv_oh_n['test_neg_root_mean_squared_error'].mean()*-1, cv_oh_nn['test_neg_root_mean_squared_error'].mean()*-1,\n","                                       cv_le_n['test_neg_root_mean_squared_error'].mean()*-1, cv_le_nn['test_neg_root_mean_squared_error'].mean()*-1],\n","                              'mae': [cv_oh_n['test_neg_mean_absolute_error'].mean()*-1, cv_oh_nn['test_neg_mean_absolute_error'].mean()*-1, \n","                                      cv_le_n['test_neg_mean_absolute_error'].mean()*-1, cv_le_nn['test_neg_mean_absolute_error'].mean()*-1]})\n","final_results = pd.concat([final_results, results])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["final_results.sort_values(by=['r2'], ascending=False)"]},{"cell_type":"markdown","metadata":{},"source":["The models we are going to select for hyperparameter tunning are the first two (```Bagging Regressor``` and ```Random Forest```), because they present the highests values of R2. \n","\n","Besides that, it's shown by the overall models' scores that those with ```One Hot enconding``` and yield values non normalized tend to have better performances. We are going to retain that for future model tuning."]},{"cell_type":"markdown","metadata":{},"source":["# Hyperparameters Tunig"]},{"cell_type":"markdown","metadata":{},"source":["## Bagging Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import KFold\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import BaggingRegressor\n","\n","# parameters to the grid\n","parameters = {\n","    'n_estimators': [100, 200, 300, 350],\n","    'max_samples': [0.7, 0.8, 0.9, 1.0],\n","    'max_features': [0.7, 0.8, 0.9, 1.0]\n","}\n","\n","metrics = {'r2': 'r2', 'rmse': 'neg_root_mean_squared_error'}\n","kf = KFold(n_splits=5, shuffle=True)\n","grid = GridSearchCV(BaggingRegressor(), param_grid=parameters, scoring=metrics, cv=kf, verbose=3, refit='r2', n_jobs=-1)\n","\n","# fitting the grid to X encoded as One Hot and y with non normalized values\n","grid.fit(X_oh, y_Nnorm)\n","results = grid.cv_results_"]},{"cell_type":"markdown","metadata":{},"source":["The best parameters to this model is the following"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["grid.best_estimator_"]},{"cell_type":"markdown","metadata":{},"source":["In order to know the performance of the best model found by ```Grid Search``` we perform a cross validation in our data and calculate the metrics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clf = grid.best_estimator_\n","scoring = ['r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_error']\n","cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n","kf = KFold(n_splits=5, shuffle=True)\n","res = cross_validate(clf, X_oh, y_Nnorm, cv=kf, scoring=scoring)\n","print('R2: ', res['test_r2'].mean())\n","print('RMSE: ', res['test_neg_root_mean_squared_error'].mean()*-1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["name_scores = ['r2']\n","colors = [\"#4C0099\", \"#FFB3B3\"]\n","\n","data = pd.DataFrame(results)\n","data = data[['param_max_features', 'param_max_samples', 'param_n_estimators', 'mean_test_r2', 'rank_test_r2']]\n","labels = [f'max_features={i}, max_samples={j}, n_estim={k}' for i,j,k in zip(data['param_max_features'],data['param_max_samples'],data['param_n_estimators'])]\n","fig, ax= plt.subplots(figsize = (12,6))\n","\n","ax.set_ylim(0.5, 1.02)\n","ax = sns.lineplot(data = data[['mean_test_r2']], palette=colors , dashes=False)\n","ax.set_xlabel(\"index\")\n","ax.set_ylabel(\"Scores\")\n","ax.set_xticks(range(len(labels)))\n","ax.set_xticklabels(labels, rotation=90, multialignment=\"left\", fontsize=8)\n","\n","for scorer, color in zip(name_scores,colors):\n","    best_index = np.nonzero(data[\"rank_test_%s\" % scorer] == 1)[0][0]\n","    best_score = data[\"mean_test_%s\" % scorer][best_index]\n","\n","    # Plot a dotted vertical line at the best score for that scorer marked by x\n","    ax.plot(\n","        [best_index, best_index],\n","        [0, best_score],\n","        linestyle=\"-.\",\n","        linewidth=1,\n","        color=color,\n","        marker=\"x\",\n","        markeredgewidth=2,\n","        ms=6,\n","    )\n","    ax.annotate(\"%0.4f\" % best_score, (best_index, best_score + 0.003))"]},{"cell_type":"markdown","metadata":{},"source":["The plot above has the goal of showing how the accuracy of the model (```R2```) varies according to the parameters we have chosen. \n","\n","For what we can see here, the most important parameter is ```max_features``` once the remarcables jumps in performance of the model comes after changes in the values of this parameter. \n","We can also notice that after ```max_features``` reaches the value of ```0.9``` few or any modifications happens in the model's performance. "]},{"cell_type":"markdown","metadata":{},"source":["Aiming to represent the predictions of the model compared with to true values of labels, we divide the data set in **train** and **test** data. With the **train** set we train the model and after predict the values of ```y```. After that we plot the predicted values faced to the true values, to see if the prediction is fair in a data set never seen by the model. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_oh, y_Nnorm, test_size=0.33, random_state=42)\n","\n","clf = grid.best_estimator_\n","clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["Accuracy (```R2```) to the data set never seen by the model:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import r2_score\n","\n","r2 = r2_score(y_pred=y_pred, y_true=y_test)\n","print(\"R2: \", r2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.scatter(y_test, y_pred,s=10,color='#9B673C')\n","plt.xlabel('True Values')\n","plt.ylabel('Predicted Values')\n","plt.title('Bagging regressor Evaluation')\n","plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='green', linewidth = 4)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["As we can see, the points are close to this \"identity line\", which represents a equality between x and y (y = x), and therefore an equality between the predicted values and true values."]},{"cell_type":"markdown","metadata":{},"source":["## Random Forest"]},{"cell_type":"markdown","metadata":{},"source":["We will do the same steps to the ```Random Forest``` model, with a slightly difference. Here we start using another function in the sklearn library, ```RandomizedSearchCV()```.\n","\n","This function selects a random combination of the grid parameters we will set at a defined number of times (defined by us). This allows us to increase the amount of parameters tested, but still keep a reasonable calculation time. We can also test the sensibility of the model to changes in parameters. If a parameter does not vary the accuracy of the model it is not worth to explore it a lot, like this we can also reduce the calculation time."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import KFold\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.ensemble import RandomForestRegressor\n","\n","parameters = {\n","    'bootstrap': [True, False],\n","    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n","    'max_features': ['sqrt', 'log2', None],\n","    'min_samples_split': [2, 5, 10],\n","    'n_estimators': [50, 100, 200]\n"," }\n","\n","metrics = {'r2': 'r2', 'rmse': 'neg_root_mean_squared_error'}\n","kf = KFold(n_splits=5, shuffle=True)\n","random_grid = RandomizedSearchCV(RandomForestRegressor(), param_distributions=parameters, scoring=metrics, cv=kf, verbose=3, refit='r2', n_jobs=-1, n_iter=40)\n","\n","random_grid.fit(X_oh, y_Nnorm)\n","results = random_grid.cv_results_"]},{"cell_type":"markdown","metadata":{},"source":["The following code aimes to show the mean accuracy of the model each time a given parameter appears, so than we can see which parameters resulted in best performance and which it is not worth to explore"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dic_res = {}\n","for i, j in zip(results['params'], results['mean_test_r2']):\n","    i = str(i)\n","    dic = {i: j}\n","    dic_res.update(dic)\n","\n","param = list(parameters.keys())\n","# print(param)\n","\n","param_grid = []\n","for p in param:\n","    values = parameters[p]\n","    for v in values:\n","        if v in ['sqrt', 'log2']:\n","            str_ = \"'\" + p + \"'\" + ': ' + \"'\" + str(v) + \"'\"\n","        else:\n","            str_ = \"'\" + p + \"'\" + ': ' + str(v)\n","        param_grid.append(str_)\n","\n","dic_levels = {}\n","l = []\n","for level in param_grid:\n","    for key in list(dic_res.keys()):\n","        if level in key:\n","            l.append(dic_res[key])\n","    dic_levels.update({level: np.array(l)})\n","    l = []\n","\n","# print(dic_levels)\n","\n","medias_por_chave = {}\n","\n","# Calcular a média para cada chave e adicionar ao novo dicionário\n","for chave, array in dic_levels.items():\n","    media = np.mean(array)\n","    sd = np.std(array)\n","    medias_por_chave[chave] = [media, sd]\n","\n","# Exibir o dicionário com as médias\n","medias_por_chave.update({\"mes\": ['mean', 'std']})\n","df_levels = pd.DataFrame(medias_por_chave).set_index('mes').T\n","df_levels = df_levels.sort_values(by='mean', ascending=False)\n","df_levels"]},{"cell_type":"markdown","metadata":{},"source":["As we can see, ```max_depth``` is important to the model, but varying its value does not change significantly the accuracy of the model. It is enough to test some values of it (the ones that resulted in best values of accuracy), but not to do an extensive research in this parameter.\n","\n","For ```min_samples_split``` equals to 5 or 10 the model has a good performance, but when it is equals to 2, the performance is way lower. A similar thing happens to ```n_estimators```.\n","\n","For ```bootstrap``` we see that the value ```False``` results better accuracy. And the same thing to ```max_features``` with the value ```None```.\n","\n","Knowing these informations, we adapt a ```GridSearchCV()``` to our data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import KFold\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestRegressor\n","\n","parameters = {\n","    'bootstrap': [False],\n","    'max_depth': [50, 60, 80, 100],\n","    'max_features': [None],          # after selecting the range of parameters that had the\n","    'min_samples_split': [5, 10],    # best performance in the previous analysis\n","    'n_estimators': [50, 100]\n","}\n","\n","metrics = {'r2': 'r2', 'rmse': 'neg_root_mean_squared_error'}\n","kf = KFold(n_splits=5, shuffle=True)\n","grid = GridSearchCV(RandomForestRegressor(), param_grid=parameters, scoring=metrics, cv=kf, verbose=2, refit='r2', n_jobs=-1)\n","\n","grid.fit(X_oh, y_Nnorm)\n","results = grid.cv_results_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["grid.best_estimator_"]},{"cell_type":"markdown","metadata":{},"source":["In order to know the performance of the best model found by ```Grid Search``` we perform a cross validation in our data and calculate the metrics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clf = grid.best_estimator_\n","scoring = ['r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_error']\n","cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n","kf = KFold(n_splits=5, shuffle=True)\n","res = cross_validate(clf, X_oh, y_Nnorm, cv=kf, scoring=scoring)\n","print('R2: ', res['test_r2'].mean())\n","print('RMSE: ', res['test_neg_root_mean_squared_error'].mean()*-1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["name_scores = ['r2']\n","colors = [\"#4C0099\", \"#FFB3B3\"]\n","\n","data = pd.DataFrame(results)\n","data = data[['param_max_depth', 'param_min_samples_split', 'param_n_estimators', 'mean_test_r2', 'rank_test_r2']]\n","labels = [f'max_depth={i}, min_samples_split={j}, n_estim={k}' for i,j,k in zip(data['param_max_depth'],data['param_min_samples_split'],data['param_n_estimators'])]\n","fig, ax= plt.subplots(figsize = (12,6))\n","\n","ax.set_ylim(0.5, 1.02)\n","ax = sns.lineplot(data = data[['mean_test_r2']], palette=colors , dashes=False)\n","ax.set_xlabel(\"index\")\n","ax.set_ylabel(\"Scores\")\n","ax.set_xticks(range(len(labels)))\n","ax.set_xticklabels(labels, rotation=90, multialignment=\"left\", fontsize=8)\n","\n","for scorer, color in zip(name_scores,colors):\n","    best_index = np.nonzero(data[\"rank_test_%s\" % scorer] == 1)[0][0]\n","    best_score = data[\"mean_test_%s\" % scorer][best_index]\n","\n","    # Plot a dotted vertical line at the best score for that scorer marked by x\n","    ax.plot(\n","        [best_index, best_index],\n","        [0, best_score],\n","        linestyle=\"-.\",\n","        linewidth=1,\n","        color=color,\n","        marker=\"x\",\n","        markeredgewidth=2,\n","        ms=6,\n","    )\n","    ax.annotate(\"%0.4f\" % best_score, (best_index, best_score + 0.003))"]},{"cell_type":"markdown","metadata":{},"source":["We can see the few or any changes happens to the accuracy of the model when we vary its parameters."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_oh, y_Nnorm, test_size=0.33, random_state=42)\n","\n","clf = grid.best_estimator_\n","clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import r2_score\n","\n","r2 = r2_score(y_pred=y_pred, y_true=y_test)\n","print(\"R2: \", r2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.scatter(y_test, y_pred,s=10,color='#9B673C')\n","plt.xlabel('True Values')\n","plt.ylabel('Predicted Values')\n","plt.title('Random Forest Evaluation')\n","plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='green', linewidth = 4)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["We get the same conclusion as the ```Bagging``` model."]},{"cell_type":"markdown","metadata":{},"source":["# Model retained and conclusions"]},{"cell_type":"markdown","metadata":{},"source":["The performance of both models are great given the regression problem we have. The predictions of both models are fair compared to the real values.\n","\n","However, the ```Bagging``` model has a slighthly higher accuracy score and therefore it is the model we retain.\n","\n","It was shown that the preprocessing of data (encoding of categorical data and normalization of numeric attibuts) had the higher impact in the performance of the model. The hyperparameters tuning has a great impact, but many values were redundant. \n","\n","For future tuning in the model we would suggest to try other practices of preprocessing data and even feature engineering. This could have a strong impact in the performance of predictions."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":1760177,"sourceId":2874008,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
